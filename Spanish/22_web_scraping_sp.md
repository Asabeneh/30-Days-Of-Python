# 30 D√≠as de Python: D√≠a 22 - Web scraping

- [D√≠a 22](#-d√≠a-22)
  - [Web scraping con Python](#web-scraping-con-python)
    - [¬øQu√© es el web scraping?](#qu√©-es-el-web-scraping)
  - [üíª Ejercicios: D√≠a 22](#-ejercicios-d√≠a-22)

# üìò D√≠a 22

## Web scraping con Python

### ¬øQu√© es el web scraping?

Internet est√° lleno de datos que pueden utilizarse para distintos fines. Para recopilar esos datos necesitamos saber c√≥mo extraerlos de sitios web.

El web scraping es el proceso de extraer y recopilar datos de sitios web y almacenarlos en una m√°quina local o en una base de datos.

En esta secci√≥n usaremos los paquetes requests y BeautifulSoup (versi√≥n 4).

Para empezar necesitas _requests_,_beautifulsoup4_ y un _sitio web_:

```sh
pip install requests
pip install beautifulsoup4
```

Para hacer scraping necesitas conocimientos b√°sicos de etiquetas HTML y selectores CSS. Usamos etiquetas HTML,clases y/o IDs para localizar contenido en la p√°gina.
Importemos requests y BeautifulSoup:

```py
import requests
from bs4 import BeautifulSoup
```

Declaremos una variable url con el sitio que queremos scrapear:

```py
import requests
from bs4 import BeautifulSoup
url = 'https://archive.ics.uci.edu/ml/datasets.php'

# Usamos requests.get para obtener datos de la URL
response = requests.get(url)
# Comprobar el estado
status = response.status_code
print(status) # 200 indica √©xito
```

```sh
200
```

Parsear el contenido con BeautifulSoup:

```py
import requests
from bs4 import BeautifulSoup
url = 'https://archive.ics.uci.edu/ml/datasets.php'

response = requests.get(url)
content = response.content # obtenemos todo el contenido del sitio
soup = BeautifulSoup(content, 'html.parser') # BeautifulSoup nos permite parsear el HTML
print(soup.title) # <title>UCI Machine Learning Repository: Data Sets</title>
print(soup.title.get_text()) # UCI Machine Learning Repository: Data Sets
print(soup.body) # muestra el cuerpo completo de la p√°gina
print(response.status_code)

tables = soup.find_all('table', {'cellpadding':'3'})
# Localizamos tablas cuyo atributo cellpadding tenga el valor 3
# Podemos usar id, class o etiquetas HTML para seleccionar elementos; consulta la documentaci√≥n de BeautifulSoup para m√°s informaci√≥n
table = tables[0] # el resultado es una lista; tomamos el primer elemento
for td in table.find('tr').find_all('td'):
    print(td.text)
```

Si ejecutas este c√≥digo ver√°s que la extracci√≥n est√° incompleta.Puedes continuar para completarla,ya que forma parte del ejercicio 1.
Consulta la documentaci√≥n de BeautifulSoup para m√°s detalles: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-start

üåï Vas por muy buen camino.Solo te faltan ocho d√≠as para alcanzar una meta impresionante.Ahora haz los ejercicios para practicar.

## üíª Ejercicios: D√≠a 22

1. Raspa el siguiente sitio y guarda los datos como un archivo JSON (url = 'http://www.bu.edu/president/boston-university-facts-stats/').
2. Extrae las tablas de esta URL (https://archive.ics.uci.edu/ml/datasets.php) y convi√©rtelas a un archivo JSON.
3. Raspa la tabla de presidentes y guarda los datos como JSON (https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States).Esta tabla no est√° muy bien estructurada,por lo que la extracci√≥n puede llevar tiempo.

üéâ ¬°Felicidades!üéâ

[<< D√≠a 21](./21_classes_and_objects_sp.md) | [D√≠a 23 >>](./23_virtual_environment_sp.md)